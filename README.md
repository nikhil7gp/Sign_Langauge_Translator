# Sign_Langauge_Translator - Machine Learning Project

A computer-visionâ€“powered project that detects hand signs and translates them into text in real time. Built using Python, OpenCV, and deep learning, this project aims to make communication easier for individuals who rely on sign language.

ğŸ¯ Overview

This project captures live hand gestures from a webcam, processes them using a trained ML model, and outputs the predicted alphabet/word as text. It serves as a practical demonstration of image classification, gesture recognition, and real-time prediction.

ğŸ” Features

Live webcam-based gesture detection

Preprocessing using OpenCV (thresholding, ROI clipping, etc.)

Deep learning model for sign classification

Real-time prediction overlay

Extendable for full Aâ€“Z sign recognition

ğŸ›  Technologies Used

Python

OpenCV

TensorFlow / Keras

NumPy & Pandas

Jupyter Notebook

ğŸš€ Project Goal

To build an accessible and easy-to-use sign language interpreting tool using machine learning and computer vision, bridging communication barriers for the hearing-impaired community.

â–¶ï¸ How to Run

Clone the repository

Install dependencies

Run the main Python file

Show hand gestures in webcam ROI to see predictions
